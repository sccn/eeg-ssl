{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T02:13:07.844415800Z",
     "start_time": "2024-07-03T02:13:07.778989Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# To be able to make edits to repo without having to restart notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T02:13:13.464613800Z",
     "start_time": "2024-07-03T02:13:11.773782600Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "data_path = Path(\"/mnt/nemar/openneuro/ds004186\")\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "from os import scandir, walk\n",
    "from signalstore import UnitOfWorkProvider\n",
    "from mongomock import MongoClient\n",
    "#from pymongo import MongoClient\n",
    "from fsspec.implementations.local import LocalFileSystem\n",
    "from fsspec import get_mapper\n",
    "from fsspec.implementations.dirfs import DirFileSystem\n",
    "import fsspec\n",
    "import mne\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Healthy Brain Network Data - Resting state\n",
    "\n",
    "This is an excerpt of the Healthy Brain Network data ([data paper](https://www.nature.com/articles/sdata2017181)). The resting state portion as been formatted with BIDS ([Brain Imaging Data Structure](https://bids-specification.readthedocs.io/en/stable/)) format, and made publicly available on [Openneuro](https://openneuro.org/datasets/ds004186/versions/2.0.0) (it's a large dataset so browsing latency might be lagging)\n",
    "\n",
    "## EEG Files\n",
    "Data is organized by subject. Each subject (`sub-*`) directory has an `eeg` directory storing the eeg data and its associated metadata.\n",
    "`*_eeg.fdt` and `*_eeg.set`: EEG data in EEGLAB format\n",
    "\n",
    "## Experiment Information\n",
    "Subjects 1-17 were instructed to attend to 'Twenty Thousand Leagues Under the Sea' (20000), played in the left ear\n",
    "Subjects 18-33 were instructed to attend to 'Journey to the Centre of the Earth' (Journey), played in the right ear\n",
    "\n",
    "## Behavioral Data\n",
    "score: Comprehension question scores for attended and unattended stories.\n",
    "Format: Subjects x Run x Story (1=Attended, 2=Unattended)\n",
    "\n",
    "## Stimuli Data Files\n",
    "\n",
    "wordVec = List of all the content words for a given trial\n",
    "onset_time = Onset time of the word in the corresponding cell of 'wordVec' (given in seconds)\n",
    "offset_time = Offset time of the word in the corresponding cell of 'wordVec' (given in seconds)\n",
    "sentence_boundaries = Time of sentence close (in seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T02:19:35.666921500Z",
     "start_time": "2024-07-03T02:19:35.573455400Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_eeg_data(bids_data_path):\n",
    "    for entry in scandir(bids_data_path):\n",
    "        if entry.is_dir() and entry.name.startswith('sub-'):\n",
    "            subject_dir = entry.name\n",
    "            subject = subject_dir.split('-')[1]\n",
    "            subject_dir_path = bids_data_path / subject_dir\n",
    "            eeg_dir = subject_dir_path / \"eeg\"\n",
    "\n",
    "            tasks = ['EC', 'EO']\n",
    "            runs  = [list(range(1, 6)), list(range(1, 6))]\n",
    "            for t, task in enumerate(tasks):\n",
    "                for run in runs[t]:\n",
    "                    # get file by name pattern subject_dir*task*run_eeg.set\n",
    "                    raw_file = eeg_dir / f\"{subject_dir}_task-{task}_run-{run}_eeg.set\"\n",
    "                    print('raw file', raw_file)\n",
    "                    if not os.path.exists(raw_file):\n",
    "                        continue\n",
    "\n",
    "                    EEG = mne.io.read_raw_eeglab(os.path.join(raw_file), preload=True)\n",
    "                    eeg_data = EEG.get_data()\n",
    "\n",
    "                    print('data shape:', eeg_data.shape)\n",
    "                    \n",
    "                    eeg_json_file = eeg_dir / f\"{subject_dir}_task-{task}_run-{run}_eeg.json\"\n",
    "                    eeg_json = json.load(eeg_json_file.open())\n",
    "                    fs = int(eeg_json['SamplingFrequency'])\n",
    "                    max_time = eeg_data.shape[1] / fs\n",
    "                    time_steps = np.linspace(0, max_time, eeg_data.shape[1]).squeeze() # in seconds\n",
    "                    print('time steps', len(time_steps))\n",
    "\n",
    "                    channel_coords_file = eeg_dir / f\"{subject_dir}_task-{task}_run-{run}_channels.tsv\"\n",
    "                    channel_coords = pd.read_csv(channel_coords_file, sep='\\t') \n",
    "                    print('channel coords file len', len(channel_coords))\n",
    "                    # get channel names from channel_coords\n",
    "                    channel_names = channel_coords['name'].values\n",
    "                    print('channel coords names', channel_names)\n",
    "                    print(len(channel_names))\n",
    "                    eeg_xarray = xr.DataArray(\n",
    "                        data=eeg_data,\n",
    "                        dims=['channel','time'],\n",
    "                        coords={\n",
    "                            'time': time_steps,\n",
    "                            'channel': channel_names\n",
    "                        },\n",
    "                        attrs={\n",
    "                            'schema_ref': 'eeg_signal',\n",
    "                            'data_name': f\"{subject_dir}_task-{task}_run-{run}\",\n",
    "                            'subject': f'{subject}',\n",
    "                            'modality': 'EEG',\n",
    "                            'task': task,d\n",
    "                            'session_run': run,\n",
    "                            'sampling_frequency': fs,\n",
    "                        }\n",
    "                    )\n",
    "                    yield eeg_xarray\n",
    "\n",
    "# count = 0\n",
    "# for eeg_xarray in load_eeg_data(data_path):\n",
    "#     if count < 10:\n",
    "#         print('adding data')\n",
    "#         # with uow_provider(dataset_name) as uow:\n",
    "#         #     uow.data.add(eeg_xarray)\n",
    "            \n",
    "#         #     uow.commit()\n",
    "#         count += 1\n",
    "#     else:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T02:13:16.127758Z",
     "start_time": "2024-07-03T02:13:15.907346500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "property model:  version_timestamp\n",
      "property model:  schema_ref\n",
      "property model:  schema_type\n",
      "property model:  schema_name\n",
      "property model:  schema_title\n",
      "property model:  schema_description\n",
      "property model:  data_name\n",
      "property model:  time_of_save\n",
      "property model:  time_of_removal\n",
      "property model:  record_type\n",
      "property model:  modality\n",
      "property model:  json_schema\n",
      "property model:  has_file\n",
      "property model:  unit_of_measure\n",
      "property model:  dimension_of_measure\n",
      "property model:  acquisition\n",
      "property model:  acquisition_date\n",
      "property model:  import_date\n",
      "property model:  acquisition_notes\n",
      "property model:  data_dimensions\n",
      "property model:  shape\n",
      "property model:  dtype\n",
      "property model:  session_description\n",
      "property model:  session_date\n",
      "property model:  session_time\n",
      "property model:  session_duration\n",
      "property model:  session_notes\n",
      "property model:  session_run\n",
      "property model:  data_ref\n",
      "property model:  start_time\n",
      "property model:  duration\n",
      "property model:  duration_unit\n",
      "property model:  animal_species\n",
      "property model:  age\n",
      "property model:  age_unit\n",
      "property model:  age_lower_bound\n",
      "property model:  age_upper_bound\n",
      "property model:  animal_id\n",
      "property model:  tetrode_id\n",
      "property model:  tetrode_depth\n",
      "property model:  genotype\n",
      "property model:  animal_strain\n",
      "property model:  stimulus_type\n",
      "property model:  stimulus_id\n",
      "property model:  stimulus_description\n",
      "property model:  recording_length\n",
      "property model:  sample_rate\n",
      "property model:  arena_shape\n",
      "property model:  arena_description\n",
      "property model:  study_description\n",
      "property model:  arena_height\n",
      "property model:  arena_width\n",
      "property model:  diameter\n",
      "property model:  arena_side_length\n",
      "property model:  arena_radius\n",
      "property model:  spike_count\n",
      "property model:  subject\n",
      "property model:  sampling_frequency\n",
      "property model:  attending_direction\n",
      "property model:  attending_story\n",
      "property model:  attend_score\n",
      "property model:  nonattend_score\n",
      "property model:  original_length\n",
      "property model:  story\n",
      "property model:  task\n",
      "meta model:  record_metamodel\n",
      "meta model:  xarray_dataarray_metamodel\n",
      "domain model:  eeg_signal\n",
      "domain model:  session\n",
      "domain model:  stimuli_record\n",
      "domain model:  wordvec\n",
      "domain model:  offset_times\n",
      "domain model:  onset_times\n",
      "domain model:  sentence_boundaries\n",
      "domain model:  envelope\n"
     ]
    }
   ],
   "source": [
    "filesystem = LocalFileSystem()\n",
    "# tmp_dir = TemporaryDirectory()\n",
    "# print(tmp_dir.name)\n",
    "\n",
    "# Create data storage location\n",
    "dataset_name = \"healthy_brain_network\"\n",
    "store_path = Path(\"/mnt/nemar/dtyoung/eeg-ssl-data/signalstore/hbn\")\n",
    "\n",
    "# Create a directory for the dataset\n",
    "if not os.path.exists(store_path):\n",
    "    os.makedirs(store_path)\n",
    "\n",
    "tmp_dir_fs = DirFileSystem(\n",
    "    store_path,\n",
    "    filesystem=filesystem\n",
    ")\n",
    "client = MongoClient()\n",
    "memory_store = {}\n",
    "uow_provider = UnitOfWorkProvider(\n",
    "    mongo_client=client,\n",
    "    filesystem=tmp_dir_fs,\n",
    "    memory_store=memory_store\n",
    ")\n",
    "import json\n",
    "cwd = Path.cwd()\n",
    "domain_models_path = cwd.parent / f\"DomainModels/{dataset_name}/data_models.json\"\n",
    "metamodel_path = cwd.parent / f\"DomainModels/{dataset_name}/metamodels.json\"\n",
    "property_path = cwd.parent / f\"DomainModels/{dataset_name}/property_models.json\"\n",
    "\n",
    "with open(metamodel_path) as f:\n",
    "    metamodels = json.load(f)\n",
    "\n",
    "with open(property_path) as f:\n",
    "    property_models = json.load(f)\n",
    "    \n",
    "# load domain models json file\n",
    "with open(domain_models_path) as f:\n",
    "    domain_models = json.load(f)\n",
    "    \n",
    "with uow_provider(dataset_name) as uow:\n",
    "    for property_model in property_models:\n",
    "        uow.domain_models.add(property_model)\n",
    "        model = uow.domain_models.get(property_model['schema_name'])\n",
    "        print('property model: ', model['schema_name'])\n",
    "    for metamodel in metamodels:\n",
    "        uow.domain_models.add(metamodel)\n",
    "        model = uow.domain_models.get(metamodel['schema_name'])\n",
    "        print('meta model: ', model['schema_name'])\n",
    "    for domain_model in domain_models:\n",
    "        uow.domain_models.add(domain_model)\n",
    "        model = uow.domain_models.get(domain_model['schema_name'])\n",
    "        print('domain model: ', model['schema_name'])\n",
    "        uow.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T02:23:15.444866400Z",
     "start_time": "2024-07-03T02:19:59.783246300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw file /mnt/nemar/openneuro/ds004186/sub-NDARRW481GFE/eeg/sub-NDARRW481GFE_task-EC_run-1_eeg.set\n",
      "Reading /mnt/nemar/openneuro/ds004186/sub-NDARRW481GFE/eeg/sub-NDARRW481GFE_task-EC_run-1_eeg.fdt\n",
      "Reading 0 ... 19997  =      0.000 ...    39.994 secs...\n",
      "data shape: (129, 19998)\n",
      "time steps 19998\n",
      "channel coords file len 129\n",
      "channel coords names ['E1' 'E2' 'E3' 'E4' 'E5' 'E6' 'E7' 'E8' 'E9' 'E10' 'E11' 'E12' 'E13'\n",
      " 'E14' 'E15' 'E16' 'E17' 'E18' 'E19' 'E20' 'E21' 'E22' 'E23' 'E24' 'E25'\n",
      " 'E26' 'E27' 'E28' 'E29' 'E30' 'E31' 'E32' 'E33' 'E34' 'E35' 'E36' 'E37'\n",
      " 'E38' 'E39' 'E40' 'E41' 'E42' 'E43' 'E44' 'E45' 'E46' 'E47' 'E48' 'E49'\n",
      " 'E50' 'E51' 'E52' 'E53' 'E54' 'E55' 'E56' 'E57' 'E58' 'E59' 'E60' 'E61'\n",
      " 'E62' 'E63' 'E64' 'E65' 'E66' 'E67' 'E68' 'E69' 'E70' 'E71' 'E72' 'E73'\n",
      " 'E74' 'E75' 'E76' 'E77' 'E78' 'E79' 'E80' 'E81' 'E82' 'E83' 'E84' 'E85'\n",
      " 'E86' 'E87' 'E88' 'E89' 'E90' 'E91' 'E92' 'E93' 'E94' 'E95' 'E96' 'E97'\n",
      " 'E98' 'E99' 'E100' 'E101' 'E102' 'E103' 'E104' 'E105' 'E106' 'E107'\n",
      " 'E108' 'E109' 'E110' 'E111' 'E112' 'E113' 'E114' 'E115' 'E116' 'E117'\n",
      " 'E118' 'E119' 'E120' 'E121' 'E122' 'E123' 'E124' 'E125' 'E126' 'E127'\n",
      " 'E128' 'Cz']\n",
      "129\n",
      "adding data\n"
     ]
    },
    {
     "ename": "MongoDAODocumentAlreadyExistsError",
     "evalue": "Cannot add document with index fields {'schema_ref': 'eeg_signal', 'data_name': 'sub-NDARRW481GFE_task-EC_run-1', 'version_timestamp': 0} because it already exists in repository.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMongoDAODocumentAlreadyExistsError\u001b[0m        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madding data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m uow_provider(dataset_name) \u001b[38;5;28;01mas\u001b[39;00m uow:\n\u001b[0;32m----> 6\u001b[0m     \u001b[43muow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43meeg_xarray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     uow\u001b[38;5;241m.\u001b[39mcommit()\n\u001b[1;32m      9\u001b[0m count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/eeg-ssl/.venv/lib/python3.10/site-packages/signalstore/store/repositories.py:591\u001b[0m, in \u001b[0;36mDataRepository.add\u001b[0;34m(self, object, data_adapter, versioning_on)\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39mattrs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion_timestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m), dttype):\n\u001b[1;32m    590\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m DataRepositoryTypeError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mversion_timestamp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdttype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m object or the integer 0, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39mattrs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mversion_timestamp\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 591\u001b[0m     ohe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_data_with_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_timestamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_timestamp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mversioning_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mversioning_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_adapter\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ohe\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/eeg-ssl/.venv/lib/python3.10/site-packages/signalstore/store/repositories.py:637\u001b[0m, in \u001b[0;36mDataRepository._add_data_with_file\u001b[0;34m(self, object, add_timestamp, versioning_on, data_adapter)\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_file\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate(\u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39mattrs)\n\u001b[0;32m--> 637\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_records\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocument\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mohe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimestamp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mversioning_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mversioning_on\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    643\u001b[0m     data_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m,\n\u001b[1;32m    644\u001b[0m     data_adapter\u001b[38;5;241m=\u001b[39mdata_adapter\n\u001b[1;32m    645\u001b[0m     )\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_operation_history\u001b[38;5;241m.\u001b[39mappend(ohe)\n",
      "File \u001b[0;32m~/eeg-ssl/.venv/lib/python3.10/site-packages/signalstore/store/data_access_objects.py:182\u001b[0m, in \u001b[0;36mMongoDAO.add\u001b[0;34m(self, document, timestamp, versioning_on)\u001b[0m\n\u001b[1;32m    180\u001b[0m document_index_args \u001b[38;5;241m=\u001b[39m {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m document\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_args}\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdocument_index_args):\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MongoDAODocumentAlreadyExistsError(\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot add document with index fields \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdocument_index_args\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because it already exists in repository.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    184\u001b[0m     )\n\u001b[1;32m    185\u001b[0m document \u001b[38;5;241m=\u001b[39m document\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    186\u001b[0m document[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_of_save\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m timestamp\n",
      "\u001b[0;31mMongoDAODocumentAlreadyExistsError\u001b[0m: Cannot add document with index fields {'schema_ref': 'eeg_signal', 'data_name': 'sub-NDARRW481GFE_task-EC_run-1', 'version_timestamp': 0} because it already exists in repository."
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for eeg_xarray in load_eeg_data(data_path):\n",
    "    if count < 10:\n",
    "        print('adding data')\n",
    "        with uow_provider(dataset_name) as uow:\n",
    "            uow.data.add(eeg_xarray)\n",
    "            \n",
    "            uow.commit()\n",
    "        count += 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "with uow_provider(dataset_name) as uow:\n",
    "    query = {\n",
    "        \"schema_ref\": \"eeg_signal\",\n",
    "        # \"subject\": \"NDARRW481GFE\",\n",
    "        \"task\": \"EC\"\n",
    "    }\n",
    "    sessions = uow.data.find(query)\n",
    "    print(len(sessions))\n",
    "    for i in range(len(sessions)):\n",
    "        print(sessions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def remove_all():\n",
    "    with uow_provider(dataset_name) as uow:\n",
    "        sessions = uow.data.find({})\n",
    "        print(len(sessions))\n",
    "        for i in range(len(sessions)):\n",
    "            uow.data.remove(session['schema_ref'], session['data_name'])\n",
    "            uow.commit()\n",
    "\n",
    "        uow.purge()\n",
    "        \n",
    "remove_all()\n",
    "with uow_provider(dataset_name) as uow:\n",
    "    sessions = uow.data.find({})\n",
    "    print(len(sessions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
