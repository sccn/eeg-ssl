{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0,'../')\n",
    "from libs.ssl_dataloader import *\n",
    "from libs.ssl_model import *\n",
    "from libs.ssl_utils import *\n",
    "from libs.eeg_utils import *\n",
    "from braindecode.preprocessing import (\n",
    "    preprocess, Preprocessor, create_fixed_length_windows)\n",
    "from braindecode.datasets import BaseDataset, BaseConcatDataset, WindowsDataset\n",
    "from braindecode.preprocessing.windowers import EEGWindowsDataset\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 87\n",
    "n_jobs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "hbn_datasets = ['ds005514','ds005512','ds005511','ds005510','ds005509','ds005508','ds005507','ds005506','ds005505']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /mnt/nemar/openneuro/ds005505/sub-NDARRD326KB9/eeg/sub-NDARRD326KB9_task-RestingState_eeg.set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dung/eeg-ssl/notebooks/../libs/ssl_dataloader.py:223: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
      "  EEG = mne.io.read_raw_eeglab(raw_file, preload=preload)\n",
      "/home/dung/eeg-ssl/notebooks/../libs/ssl_dataloader.py:223: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  EEG = mne.io.read_raw_eeglab(raw_file, preload=preload)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /mnt/nemar/openneuro/ds005505/sub-NDARZD415ZZ1/eeg/sub-NDARZD415ZZ1_task-RestingState_eeg.set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dung/eeg-ssl/notebooks/../libs/ssl_dataloader.py:223: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
      "  EEG = mne.io.read_raw_eeglab(raw_file, preload=preload)\n",
      "/home/dung/eeg-ssl/notebooks/../libs/ssl_dataloader.py:223: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  EEG = mne.io.read_raw_eeglab(raw_file, preload=preload)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /mnt/nemar/openneuro/ds005505/sub-NDARXH597ML1/eeg/sub-NDARXH597ML1_task-RestingState_eeg.set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dung/eeg-ssl/notebooks/../libs/ssl_dataloader.py:223: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
      "  EEG = mne.io.read_raw_eeglab(raw_file, preload=preload)\n",
      "/home/dung/eeg-ssl/notebooks/../libs/ssl_dataloader.py:223: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  EEG = mne.io.read_raw_eeglab(raw_file, preload=preload)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /mnt/nemar/openneuro/ds005510/sub-NDARAE877NER/eeg/sub-NDARAE877NER_task-RestingState_eeg.set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dung/eeg-ssl/notebooks/../libs/ssl_dataloader.py:223: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
      "  EEG = mne.io.read_raw_eeglab(raw_file, preload=preload)\n",
      "/home/dung/eeg-ssl/notebooks/../libs/ssl_dataloader.py:223: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  EEG = mne.io.read_raw_eeglab(raw_file, preload=preload)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /mnt/nemar/openneuro/ds005510/sub-NDARYW984FLT/eeg/sub-NDARYW984FLT_task-RestingState_eeg.set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dung/eeg-ssl/notebooks/../libs/ssl_dataloader.py:223: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
      "  EEG = mne.io.read_raw_eeglab(raw_file, preload=preload)\n",
      "/home/dung/eeg-ssl/notebooks/../libs/ssl_dataloader.py:223: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  EEG = mne.io.read_raw_eeglab(raw_file, preload=preload)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /mnt/nemar/openneuro/ds005510/sub-NDARFX710UZA/eeg/sub-NDARFX710UZA_task-RestingState_eeg.set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dung/eeg-ssl/notebooks/../libs/ssl_dataloader.py:223: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
      "  EEG = mne.io.read_raw_eeglab(raw_file, preload=preload)\n",
      "/home/dung/eeg-ssl/notebooks/../libs/ssl_dataloader.py:223: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  EEG = mne.io.read_raw_eeglab(raw_file, preload=preload)\n"
     ]
    }
   ],
   "source": [
    "ds1 = HBNDataset('ds005505', tasks=['RestingState'], subjects=['NDARRD326KB9', 'NDARZD415ZZ1', 'NDARXH597ML1'])\n",
    "ds2 = HBNDataset('ds005510', tasks=['RestingState'], subjects=['NDARAE877NER', 'NDARYW984FLT', 'NDARFX710UZA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ds = BaseConcatDataset([ds1, ds2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dung/eeg-ssl/.venv/lib/python3.10/site-packages/braindecode/preprocessing/preprocess.py:55: UserWarning: Preprocessing choices with lambda functions cannot be saved.\n",
      "  warn('Preprocessing choices with lambda functions cannot be saved.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up low-pass filter at 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal lowpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 221 samples (0.442 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up low-pass filter at 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal lowpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 221 samples (0.442 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up low-pass filter at 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal lowpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 221 samples (0.442 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up low-pass filter at 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal lowpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 221 samples (0.442 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up low-pass filter at 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal lowpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 221 samples (0.442 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up low-pass filter at 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal lowpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 221 samples (0.442 s)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<braindecode.datasets.base.BaseConcatDataset at 0x7f83b08a57b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import multiply\n",
    "high_cut_hz = 30\n",
    "# Factor to convert from V to uV\n",
    "factor = 1e6\n",
    "preprocessors = [\n",
    "    Preprocessor(lambda data: multiply(data, factor)),  # Convert from V to uV\n",
    "    Preprocessor('filter', l_freq=None, h_freq=high_cut_hz, n_jobs=n_jobs)\n",
    "]\n",
    "\n",
    "# Transform the data\n",
    "preprocess(all_ds, preprocessors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_len_s = 30\n",
    "fs = all_ds.datasets[0].raw.info['sfreq']\n",
    "window_len_samples = int(fs * window_len_s)\n",
    "window_stride_samples = int(fs * 4)\n",
    "# window_stride_samples = int(fs * window_len_s)\n",
    "windows_ds = create_fixed_length_windows(\n",
    "    all_ds, start_offset_samples=0, stop_offset_samples=None,\n",
    "    window_size_samples=window_len_samples,\n",
    "    window_stride_samples=window_stride_samples, drop_last_window=True,\n",
    "    preload=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dung/eeg-ssl/.venv/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:265: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/home/dung/eeg-ssl/.venv/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:265: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/home/dung/eeg-ssl/.venv/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:265: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/home/dung/eeg-ssl/.venv/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:265: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<braindecode.datasets.base.BaseConcatDataset at 0x7f82301d2230>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import scale as standard_scale\n",
    "\n",
    "preprocess(windows_ds, [Preprocessor(standard_scale, channel_wise=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from braindecode.datasets import BaseConcatDataset\n",
    "\n",
    "subjects = np.unique(windows_ds.description['subject'])\n",
    "subj_train, subj_test = train_test_split(\n",
    "    subjects, test_size=0.4, random_state=random_state)\n",
    "subj_valid, subj_test = train_test_split(\n",
    "    subj_test, test_size=0.5, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelativePositioningDataset(BaseConcatDataset):\n",
    "    \"\"\"BaseConcatDataset with __getitem__ that expects 2 indices and a target.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, list_of_ds):\n",
    "        super().__init__(list_of_ds)\n",
    "        self.return_pair = True\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.return_pair:\n",
    "            ind1, ind2, y = index\n",
    "            return (super().__getitem__(ind1)[0],\n",
    "                    super().__getitem__(ind2)[0]), y\n",
    "        else:\n",
    "            return super().__getitem__(index)\n",
    "\n",
    "    @property\n",
    "    def return_pair(self):\n",
    "        return self._return_pair\n",
    "\n",
    "    @return_pair.setter\n",
    "    def return_pair(self, value):\n",
    "        self._return_pair = value\n",
    "\n",
    "\n",
    "split_ids = {'train': subj_train, 'valid': subj_valid, 'test': subj_test}\n",
    "splitted = dict()\n",
    "for name, values in split_ids.items():\n",
    "    splitted[name] = RelativePositioningDataset(\n",
    "        [ds for ds in windows_ds.datasets\n",
    "         if ds.description['subject'] in values])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i_window_in_trial</th>\n",
       "      <th>i_start_in_trial</th>\n",
       "      <th>i_stop_in_trial</th>\n",
       "      <th>target</th>\n",
       "      <th>task</th>\n",
       "      <th>session</th>\n",
       "      <th>run</th>\n",
       "      <th>subject</th>\n",
       "      <th>sfreq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15000</td>\n",
       "      <td>-1</td>\n",
       "      <td>RestingState</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NDARZD415ZZ1</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>17000</td>\n",
       "      <td>-1</td>\n",
       "      <td>RestingState</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NDARZD415ZZ1</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4000</td>\n",
       "      <td>19000</td>\n",
       "      <td>-1</td>\n",
       "      <td>RestingState</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NDARZD415ZZ1</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6000</td>\n",
       "      <td>21000</td>\n",
       "      <td>-1</td>\n",
       "      <td>RestingState</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NDARZD415ZZ1</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8000</td>\n",
       "      <td>23000</td>\n",
       "      <td>-1</td>\n",
       "      <td>RestingState</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NDARZD415ZZ1</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>154000</td>\n",
       "      <td>169000</td>\n",
       "      <td>-1</td>\n",
       "      <td>RestingState</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NDARYW984FLT</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78</td>\n",
       "      <td>156000</td>\n",
       "      <td>171000</td>\n",
       "      <td>-1</td>\n",
       "      <td>RestingState</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NDARYW984FLT</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79</td>\n",
       "      <td>158000</td>\n",
       "      <td>173000</td>\n",
       "      <td>-1</td>\n",
       "      <td>RestingState</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NDARYW984FLT</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>160000</td>\n",
       "      <td>175000</td>\n",
       "      <td>-1</td>\n",
       "      <td>RestingState</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NDARYW984FLT</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>81</td>\n",
       "      <td>162000</td>\n",
       "      <td>177000</td>\n",
       "      <td>-1</td>\n",
       "      <td>RestingState</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NDARYW984FLT</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>301 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    i_window_in_trial  i_start_in_trial  i_stop_in_trial  target  \\\n",
       "0                   0                 0            15000      -1   \n",
       "1                   1              2000            17000      -1   \n",
       "2                   2              4000            19000      -1   \n",
       "3                   3              6000            21000      -1   \n",
       "4                   4              8000            23000      -1   \n",
       "..                ...               ...              ...     ...   \n",
       "77                 77            154000           169000      -1   \n",
       "78                 78            156000           171000      -1   \n",
       "79                 79            158000           173000      -1   \n",
       "80                 80            160000           175000      -1   \n",
       "81                 81            162000           177000      -1   \n",
       "\n",
       "            task session run       subject  sfreq  \n",
       "0   RestingState              NDARZD415ZZ1    500  \n",
       "1   RestingState              NDARZD415ZZ1    500  \n",
       "2   RestingState              NDARZD415ZZ1    500  \n",
       "3   RestingState              NDARZD415ZZ1    500  \n",
       "4   RestingState              NDARZD415ZZ1    500  \n",
       "..           ...     ...  ..           ...    ...  \n",
       "77  RestingState              NDARYW984FLT    500  \n",
       "78  RestingState              NDARYW984FLT    500  \n",
       "79  RestingState              NDARYW984FLT    500  \n",
       "80  RestingState              NDARYW984FLT    500  \n",
       "81  RestingState              NDARYW984FLT    500  \n",
       "\n",
       "[301 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted['train'].get_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.samplers import RelativePositioningSampler\n",
    "\n",
    "sfreq = 500\n",
    "tau_pos, tau_neg = int(sfreq * 60), int(sfreq * 2 * 60)\n",
    "n_examples_train = 250 * len(splitted['train'].datasets)\n",
    "n_examples_valid = 250 * len(splitted['valid'].datasets)\n",
    "n_examples_test = 250 * len(splitted['test'].datasets)\n",
    "\n",
    "train_sampler = RelativePositioningSampler(\n",
    "    splitted['train'].get_metadata(), tau_pos=tau_pos, tau_neg=tau_neg,\n",
    "    n_examples=n_examples_train, same_rec_neg=True, random_state=random_state)\n",
    "valid_sampler = RelativePositioningSampler(\n",
    "    splitted['valid'].get_metadata(), tau_pos=tau_pos, tau_neg=tau_neg,\n",
    "    n_examples=n_examples_valid, same_rec_neg=True,\n",
    "    random_state=random_state).presample()\n",
    "test_sampler = RelativePositioningSampler(\n",
    "    splitted['test'].get_metadata(), tau_pos=tau_pos, tau_neg=tau_neg,\n",
    "    n_examples=n_examples_test, same_rec_neg=True,\n",
    "    random_state=random_state).presample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models import SleepStagerChambon2018\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device == 'cuda':\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "# Set random seed to be able to roughly reproduce results\n",
    "# Note that with cudnn benchmark set to True, GPU indeterminism\n",
    "# may still make results substantially different between runs.\n",
    "# To obtain more consistent results at the cost of increased computation time,\n",
    "# you can set `cudnn_benchmark=False` in `set_random_seeds`\n",
    "# or remove `torch.backends.cudnn.benchmark = True`\n",
    "set_random_seeds(seed=random_state, cuda=device == 'cuda')\n",
    "\n",
    "# Extract number of channels and time steps from dataset\n",
    "n_channels, input_size_samples = windows_ds[0][0].shape\n",
    "emb_size = 100\n",
    "classes = list(range(5))\n",
    "\n",
    "emb = SleepStagerChambon2018(\n",
    "    n_channels,\n",
    "    sfreq,\n",
    "    n_outputs=emb_size,\n",
    "    n_conv_chs=16,\n",
    "    n_times=input_size_samples,\n",
    "    dropout=0,\n",
    "    apply_batch_norm=True,\n",
    ")\n",
    "\n",
    "\n",
    "class ContrastiveNet(nn.Module):\n",
    "    \"\"\"Contrastive module with linear layer on top of siamese embedder.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    emb : nn.Module\n",
    "        Embedder architecture.\n",
    "    emb_size : int\n",
    "        Output size of the embedder.\n",
    "    dropout : float\n",
    "        Dropout rate applied to the linear layer of the contrastive module.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, emb, emb_size, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.emb = emb\n",
    "        self.clf = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(emb_size, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1, x2 = x\n",
    "        z1, z2 = self.emb(x1), self.emb(x2)\n",
    "        return self.clf(torch.abs(z1 - z2)).flatten()\n",
    "\n",
    "\n",
    "model = ContrastiveNet(emb, emb_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_acc    train_loss    valid_acc    valid_loss    cp      dur\n",
      "-------  -----------  ------------  -----------  ------------  ----  -------\n",
      "      1       \u001b[36m0.8038\u001b[0m        \u001b[32m0.5658\u001b[0m       \u001b[35m0.6880\u001b[0m        \u001b[31m0.5976\u001b[0m     +  42.1334\n",
      "      2       \u001b[36m0.8777\u001b[0m        \u001b[32m0.3160\u001b[0m       \u001b[35m0.7400\u001b[0m        \u001b[31m0.5794\u001b[0m     +  43.0816\n",
      "      3       \u001b[36m0.8992\u001b[0m        \u001b[32m0.2981\u001b[0m       0.6720        \u001b[31m0.5500\u001b[0m     +  49.1422\n",
      "      4       \u001b[36m0.9046\u001b[0m        \u001b[32m0.2479\u001b[0m       0.6240        0.8002        48.7186\n",
      "      5       \u001b[36m0.9301\u001b[0m        \u001b[32m0.2285\u001b[0m       0.5760        1.1914        49.1837\n",
      "      6       0.9194        0.2539       0.6280        0.7326        49.1231\n",
      "      7       \u001b[36m0.9341\u001b[0m        \u001b[32m0.1808\u001b[0m       0.7360        \u001b[31m0.4952\u001b[0m     +  49.0041\n",
      "      8       0.9167        0.2594       \u001b[35m0.7600\u001b[0m        0.5544        48.7554\n",
      "      9       \u001b[36m0.9435\u001b[0m        \u001b[32m0.1749\u001b[0m       \u001b[35m0.8160\u001b[0m        \u001b[31m0.4511\u001b[0m     +  48.8163\n",
      "     10       \u001b[36m0.9570\u001b[0m        \u001b[32m0.1334\u001b[0m       0.6560        0.8971        49.1937\n",
      "     11       0.9395        0.1830       0.6760        0.7021        48.7823\n",
      "     12       0.9301        0.2270       0.6120        0.7393        49.0654\n",
      "     13       0.9247        0.2030       0.6000        1.3573        49.0582\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from skorch.helper import predefined_split\n",
    "from skorch.callbacks import Checkpoint, EarlyStopping, EpochScoring\n",
    "from braindecode import EEGClassifier\n",
    "\n",
    "lr = 5e-3\n",
    "batch_size = 12  # 512 if data large enough\n",
    "n_epochs = 25\n",
    "num_workers = 0 if n_jobs <= 1 else n_jobs\n",
    "\n",
    "cp = Checkpoint(dirname='', f_criterion=None, f_optimizer=None, f_history=None)\n",
    "early_stopping = EarlyStopping(patience=10)\n",
    "train_acc = EpochScoring(\n",
    "    scoring='accuracy', on_train=True, name='train_acc', lower_is_better=False)\n",
    "\n",
    "callbacks = [\n",
    "    ('cp', cp),\n",
    "    ('patience', early_stopping),\n",
    "    ('train_acc', train_acc),\n",
    "]\n",
    "\n",
    "clf = EEGClassifier(\n",
    "    model,\n",
    "    criterion=torch.nn.BCEWithLogitsLoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    max_epochs=n_epochs,\n",
    "    iterator_train__shuffle=False,\n",
    "    iterator_train__sampler=train_sampler,\n",
    "    iterator_valid__sampler=valid_sampler,\n",
    "    iterator_train__num_workers=num_workers,\n",
    "    iterator_valid__num_workers=num_workers,\n",
    "    train_split=predefined_split(splitted['valid']),\n",
    "    optimizer__lr=lr,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=callbacks,\n",
    "    device=device,\n",
    "    classes=classes,\n",
    ")\n",
    "# Model training for a specified number of epochs. `y` is None as it is already\n",
    "# supplied in the dataset.\n",
    "clf.fit(splitted['train'], y=None)\n",
    "clf.load_params(checkpoint=cp)  # Load the model with the lowest valid_loss\n",
    "\n",
    "os.remove('./params.pt')  # Delete parameters file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import torch\n",
    "from torch import nn\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models import SleepStagerChambon2018\n",
    "# Extract number of channels and time steps from dataset\n",
    "n_channels, input_size_samples = windows_ds[0][0].shape\n",
    "emb_size = 100\n",
    "classes = list(range(5))\n",
    "\n",
    "emb = SleepStagerChambon2018(\n",
    "    n_channels,\n",
    "    sfreq,\n",
    "    n_outputs=emb_size,\n",
    "    n_conv_chs=16,\n",
    "    n_times=input_size_samples,\n",
    "    dropout=0,\n",
    "    apply_batch_norm=True,\n",
    ")\n",
    "\n",
    "# define the LightningModule\n",
    "class LitSSL(L.LightningModule):\n",
    "    def __init__(self, emb, emb_size, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.emb = emb\n",
    "        self.clf = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(emb_size, 1)\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        X, y = batch\n",
    "        x1, x2 = X[0], X[1]\n",
    "        z1, z2 = self.emb(x1), self.emb(x2)\n",
    "        loss = nn.functional.binary_cross_entropy_with_logits(self.clf(torch.abs(z1 - z2)).flatten(), y)\n",
    "\n",
    "        # Logging to TensorBoard (if installed) by default\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "model =  LitSSL(emb, emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type                   | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | emb  | SleepStagerChambon2018 | 704 K  | train\n",
      "1 | clf  | Sequential             | 101    | train\n",
      "--------------------------------------------------------\n",
      "704 K     Trainable params\n",
      "0         Non-trainable params\n",
      "704 K     Total params\n",
      "2.817     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/63 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 63/63 [00:23<00:00,  2.68it/s, v_num=5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 63/63 [00:23<00:00,  2.67it/s, v_num=5]\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(splitted['train'], sampler=train_sampler, batch_size=12, num_workers=4)\n",
    "# train the model (hint: here are some helpful Trainer arguments for rapid idea iteration)\n",
    "trainer = L.Trainer(limit_train_batches=100, max_epochs=1, accelerator='gpu')\n",
    "trainer.fit(model=model, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
