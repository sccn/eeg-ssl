{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a7ac961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../')\n",
    "from libs.ssl_task import Classification\n",
    "from libs.ssl_data import SSLHBNDataModule\n",
    "from torchmetrics.functional import f1_score, accuracy\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e338138",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdt-young112\u001b[0m (\u001b[33msccn\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/dung/eeg-ssl/notebooks/wandb/run-20250531_112049-0hnnqhns</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sccn/hbn-regression/runs/0hnnqhns' target=\"_blank\">fiery-brook-140</a></strong> to <a href='https://wandb.ai/sccn/hbn-regression' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sccn/hbn-regression' target=\"_blank\">https://wandb.ai/sccn/hbn-regression</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sccn/hbn-regression/runs/0hnnqhns' target=\"_blank\">https://wandb.ai/sccn/hbn-regression/runs/0hnnqhns</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "run = wandb.init(project=\"hbn-regression\", job_type=\"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d589de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "model = \"FGVsQMup\" \n",
    "artifact_dir = f'artifacts/model-{model}'\n",
    "version = 0\n",
    "if os.path.exists(f'{artifact_dir}:v{version}'):\n",
    "    print(f\"Artifact directory {artifact_dir}:v{version} already exists. Skipping download.\")\n",
    "else:\n",
    "    artifact = run.use_artifact(f'sccn/hbn-regression/model-{model}:v{version}', type='model')\n",
    "    artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4da958ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data module...\n",
      "Number of subjects in balanced dataset: 92\n",
      "Gender distribution in balanced dataset: (array(['F', 'M'], dtype='<U1'), array([46, 46]))\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import lightning as L\n",
    "with open('../runs/config_Classification.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "ssl_task = Classification()\n",
    "config['data']['ssl_task'] = ssl_task\n",
    "config['data']['cache_dir'] = \"data\"\n",
    "config['data']['num_workers'] = 2\n",
    "config['data']['mapping'] = {'F': 1, 'M': 0}\n",
    "\n",
    "config['model']['init_args']['emb_size'] = 100\n",
    "config['model']['init_args']['encoder_emb_size'] = 100\n",
    "config['model']['init_args']['encoder_path'] = \"braindecode.models.Deep4Net\"\n",
    "config['model']['init_args']['encoder_kwargs']['n_chans'] = 128\n",
    "config['model']['init_args']['window_norm'] = 'channel_wise'\n",
    "\n",
    "config['trainer']['callbacks'] = None\n",
    "config['trainer']['logger'] = None\n",
    "\n",
    "trainer = L.Trainer(**config['trainer'])\n",
    "mode = 'validate'\n",
    "print('Loading data module...')\n",
    "litDataModule = SSLHBNDataModule(**config['data'])\n",
    "litDataModule.setup(stage=mode)\n",
    "val_dataloader = litDataModule.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "202abcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def rankme(embeddings):\n",
    "        # parse inputs\n",
    "        # print('RankMe self.embs', self.embs)\n",
    "        embs = embeddings\n",
    "        if len(embs.shape) > 2:\n",
    "            raise ValueError('Expect 2D embeddings of shape (N, K)')\n",
    "        print('RankMe embs shape', embs.shape)\n",
    "        if embs.shape[0] < embs.shape[1]:\n",
    "            raise ValueError(f'Expect N >= K but received ({embs.shape})')\n",
    "        # subselect 25600 embeddings randomly\n",
    "        # embs = embs[torch.randperm(embs.shape[0])[:25600]]\n",
    "        _, S, _ = torch.linalg.svd(embs)\n",
    "        eps = 1e-7\n",
    "        p = S/torch.linalg.norm(S, ord=1) + eps\n",
    "        rank_z = torch.exp(-torch.sum(p*torch.log(p)))\n",
    "\n",
    "        return rank_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1a8d8a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(x):\n",
    "    center, _ = x.median(dim=-1, keepdim=True)\n",
    "    variance = x.quantile(0.75, dim=-1, keepdim=True) - x.quantile(0.25, dim=-1, keepdim=True)\n",
    "    x = (x - center) / variance # normalize preserving batch dim\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "31895ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train releases: ['ds005506', 'ds005507', 'ds005508', 'ds005509', 'ds005511', 'ds005512', 'ds005514', 'ds005515', 'ds005516']\n",
      "Validation release: ds005505\n",
      "Test release: ds005510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects in balanced dataset: 92\n",
      "Gender distribution in balanced dataset: (array(['F', 'M'], dtype='<U1'), array([46, 46]))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55039789a26449e7a7b0fe0a5e01fb3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">         Validate metric         </span>┃<span style=\"font-weight: bold\">          DataLoader 0           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     val_Classifier/accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       0.49395859241485596       </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        val_Classifier/f1        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       0.3855990171432495        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_Classifier/loss       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       0.6977773904800415        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> val_Classifier/subject_accuracy </span>│<span style=\"color: #800080; text-decoration-color: #800080\">               0.5               </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    val_Classifier/subject_f1    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       0.6666666865348816        </span>│\n",
       "└─────────────────────────────────┴─────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m        Validate metric        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m         DataLoader 0          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m    val_Classifier/accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      0.49395859241485596      \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       val_Classifier/f1       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      0.3855990171432495       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_Classifier/loss      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      0.6977773904800415       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mval_Classifier/subject_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m              0.5              \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   val_Classifier/subject_f1   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      0.6666666865348816       \u001b[0m\u001b[35m \u001b[0m│\n",
       "└─────────────────────────────────┴─────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy tensor(0.4939)\n",
      "RankMe embs shape torch.Size([18787, 200])\n",
      "RankMe score tensor(129.6006)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "config['trainer']['callbacks'] = None\n",
    "config['trainer']['logger'] = None\n",
    "\n",
    "trainer = L.Trainer(**config['trainer'])\n",
    "model = Classification.ClassificationLit(**config['model']['init_args'])\n",
    "scores = trainer.validate(model=model, datamodule=litDataModule)\n",
    "embeddings= []\n",
    "preds = []\n",
    "labels = []\n",
    "model = model.to('cpu')\n",
    "model.eval()\n",
    "final_layer = copy.deepcopy(model.encoder.final_layer)\n",
    "del model.encoder.final_layer\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader:\n",
    "        X, Y = batch[0], batch[1]\n",
    "        Y = Y.to(torch.long)\n",
    "        X = model.remove_chan(X)\n",
    "        X = normalize_data(X)\n",
    "        Z = model.encoder(X)\n",
    "        embeddings.append(Z.squeeze().cpu())\n",
    "\n",
    "        Z = final_layer(Z)\n",
    "        _, pred = Z.max(1)\n",
    "\n",
    "        preds.append(pred.cpu())\n",
    "        labels.append(Y.cpu())\n",
    "        \n",
    "embeddings= torch.cat(embeddings, dim=0)\n",
    "preds = torch.cat(preds, dim=0)\n",
    "Y = torch.cat(labels, dim=0)\n",
    "print('accuracy', accuracy(preds, Y, task='binary', num_classes=2))\n",
    "print('RankMe score', rankme(embeddings))\n",
    "# print(calculate_rankme(embeddings_best.detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5e1c4c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from artifacts/model-FGVsQMup:v0/model.ckpt...\n",
      "Train releases: ['ds005506', 'ds005507', 'ds005508', 'ds005509', 'ds005511', 'ds005512', 'ds005514', 'ds005515', 'ds005516']\n",
      "Validation release: ds005505\n",
      "Test release: ds005510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at artifacts/model-FGVsQMup:v0/model.ckpt\n",
      "/home/dung/eeg-ssl/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:277: Be aware that when using `ckpt_path`, callbacks used to create the checkpoint need to be provided during `Trainer` instantiation. Please add the following callbacks: [\"ModelCheckpoint{'monitor': 'val_Classifier/accuracy', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}\"].\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at artifacts/model-FGVsQMup:v0/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects in balanced dataset: 92\n",
      "Gender distribution in balanced dataset: (array(['F', 'M'], dtype='<U1'), array([46, 46]))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f5e6d5b5d3b43efbdd9f33811e70f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">         Validate metric         </span>┃<span style=\"font-weight: bold\">          DataLoader 0           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     val_Classifier/accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       0.8585191965103149        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        val_Classifier/f1        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.469867467880249        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_Classifier/loss       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       0.3957620859146118        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> val_Classifier/subject_accuracy </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       0.8695651888847351        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    val_Classifier/subject_f1    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       0.8571428656578064        </span>│\n",
       "└─────────────────────────────────┴─────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m        Validate metric        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m         DataLoader 0          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m    val_Classifier/accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      0.8585191965103149       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       val_Classifier/f1       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.469867467880249       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_Classifier/loss      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      0.3957620859146118       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mval_Classifier/subject_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      0.8695651888847351       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   val_Classifier/subject_f1   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      0.8571428656578064       \u001b[0m\u001b[35m \u001b[0m│\n",
       "└─────────────────────────────────┴─────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds shape: torch.Size([18787])\n",
      "accuracy tensor(0.8585)\n",
      "RankMe embs shape torch.Size([18787, 200])\n",
      "RankMe score tensor(12.1231)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "version = 0\n",
    "artifact_path = f'artifacts/model-FGVsQMup:v{version}/model.ckpt'\n",
    "print(f'Loading model from {artifact_path}...')\n",
    "config['trainer']['callbacks'] = None\n",
    "config['trainer']['logger'] = None\n",
    "\n",
    "trainer = L.Trainer(**config['trainer'])\n",
    "model = Classification.ClassificationLit(**config['model']['init_args'])\n",
    "scores = trainer.validate(model=model, ckpt_path=artifact_path, datamodule=litDataModule)\n",
    "model_best = Classification.ClassificationLit.load_from_checkpoint(artifact_path, **config['model']['init_args'])\n",
    "embeddings_best = []\n",
    "preds = []\n",
    "labels = []\n",
    "model_best = model_best.to('cpu')\n",
    "model_best.eval()\n",
    "final_layer = copy.deepcopy(model_best.encoder.final_layer)\n",
    "del model_best.encoder.final_layer\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader:\n",
    "        X, Y = batch[0], batch[1]\n",
    "        Y = Y.to(torch.long)\n",
    "        X = model_best.remove_chan(X)\n",
    "        X = normalize_data(X)\n",
    "        Z = model_best.encoder(X)\n",
    "        embeddings_best.append(Z.squeeze().cpu())\n",
    "\n",
    "        Z = final_layer(Z)\n",
    "        _, pred = Z.max(1)\n",
    "\n",
    "        preds.append(pred.cpu())\n",
    "        labels.append(Y.cpu())\n",
    "        \n",
    "embeddings_best= torch.cat(embeddings_best, dim=0)\n",
    "preds = torch.cat(preds, dim=0)\n",
    "print('preds shape:', preds.shape)\n",
    "Y = torch.cat(labels, dim=0)\n",
    "print('accuracy', accuracy(preds, Y, task='binary', num_classes=2))\n",
    "print('RankMe score', rankme(embeddings_best))\n",
    "# print(calculate_rankme(embeddings_best.detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75287f63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245d6d87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
